{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "034a0590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12920 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12920/12920 [00:00<00:00, 22799.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3185/3185 [00:00<00:00, 18733.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building GT matrix...\n",
      "Training classifiers...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 141\u001b[0m\n\u001b[1;32m    138\u001b[0m A \u001b[38;5;241m=\u001b[39m build_gt_matrix(d, m, method\u001b[38;5;241m=\u001b[39mGT_type)\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining classifiers...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 141\u001b[0m classifiers \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_classifiers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicting test scores...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    144\u001b[0m Y_scores \u001b[38;5;241m=\u001b[39m predict_all_scores(X_test, classifiers, A)\n",
      "Cell \u001b[0;32mIn[3], line 75\u001b[0m, in \u001b[0;36mtrain_classifiers\u001b[0;34m(X, Y, A)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m issparse, csr_matrix\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, csr_matrix), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX must be in CSR format\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 75\u001b[0m Z \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m classifiers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import hamming_loss\n",
    "from scipy.sparse import lil_matrix\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# -----------------------------\n",
    "# Parameters\n",
    "# -----------------------------\n",
    "k = 10\n",
    "m = 240\n",
    "e = 30\n",
    "GT_type = \"sparse_rand\"\n",
    "\n",
    "# -----------------------------\n",
    "# Dataset Loader for Delicious\n",
    "# -----------------------------\n",
    "def load_delicious_dataset(info_path, data_path, n_samples):\n",
    "    with open(info_path, 'r') as f:\n",
    "        line = f.readline()\n",
    "        num_labels, num_features, _ = map(int, line.strip().split())\n",
    "\n",
    "    X = lil_matrix((n_samples, num_features), dtype=np.float32)\n",
    "    Y = np.zeros((n_samples, num_labels), dtype=np.int32)\n",
    "\n",
    "    with open(data_path, 'r') as f:\n",
    "        for i, line in tqdm(enumerate(f), total=n_samples):\n",
    "            if i >= n_samples:\n",
    "                break\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 2:\n",
    "                continue\n",
    "            labels = parts[0].split(',')\n",
    "            features = parts[1:]\n",
    "\n",
    "            for l in labels:\n",
    "                try:\n",
    "                    idx = int(l)\n",
    "                    if 0 <= idx < num_labels:\n",
    "                        Y[i, idx] = 1\n",
    "                except ValueError:\n",
    "                    pass\n",
    "\n",
    "            for item in features:\n",
    "                if ':' in item:\n",
    "                    try:\n",
    "                        idx, val = item.split(':')\n",
    "                        idx = int(idx)\n",
    "                        val = float(val)\n",
    "                        if 0 <= idx < num_features:\n",
    "                            X[i, idx] = val\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "\n",
    "    return X.tocsr(), Y, num_features, num_labels\n",
    "\n",
    "# -----------------------------\n",
    "# GT Matrix Builder\n",
    "# -----------------------------\n",
    "def build_gt_matrix(d, m, method=\"sparse_rand\"):\n",
    "    A = np.zeros((m, d), dtype=int)\n",
    "    s = int(np.ceil(np.log2(d)))  # ensure better disjunct properties\n",
    "    for j in range(d):\n",
    "        ones = np.random.choice(m, size=s, replace=False)\n",
    "        A[ones, j] = 1\n",
    "    return A\n",
    "\n",
    "# -----------------------------\n",
    "# MLGT Training (Algorithm 1)\n",
    "# -----------------------------\n",
    "def train_classifiers(X, Y, A):\n",
    "    from scipy.sparse import issparse, csr_matrix\n",
    "    assert isinstance(X, csr_matrix), \"X must be in CSR format\"\n",
    "    Z = (Y @ A.T > 0).astype(int)\n",
    "\n",
    "    classifiers = []\n",
    "    for j in tqdm(range(A.shape[0])):\n",
    "        clf = LogisticRegression(solver='saga', max_iter=300, n_jobs=-1, random_state=42)\n",
    "        clf.fit(X, Z[:, j])\n",
    "        classifiers.append(clf)\n",
    "    return classifiers\n",
    "\n",
    "# -----------------------------\n",
    "# MLGT Prediction with Probabilities\n",
    "# -----------------------------\n",
    "def predict_all_scores(X, classifiers, A):\n",
    "    m = len(classifiers)\n",
    "    Z_hat = np.zeros((X.shape[0], m))\n",
    "    for j, clf in enumerate(classifiers):\n",
    "        Z_hat[:, j] = clf.predict_proba(X)[:, 1]  # probability of label 1\n",
    "\n",
    "    Y_scores = np.zeros((X.shape[0], A.shape[1]))\n",
    "    for l in range(A.shape[1]):\n",
    "        rows = np.where(A[:, l] == 1)[0]\n",
    "        Y_scores[:, l] = np.sum(Z_hat[:, rows], axis=1)\n",
    "    return Y_scores\n",
    "\n",
    "# -----------------------------\n",
    "# Thresholding for binary prediction\n",
    "# -----------------------------\n",
    "def threshold_predictions(Y_scores, A, e):\n",
    "    Y_pred = np.zeros_like(Y_scores, dtype=int)\n",
    "    for l in range(A.shape[1]):\n",
    "        rows = np.where(A[:, l] == 1)[0]\n",
    "        for i in range(Y_scores.shape[0]):\n",
    "            support_misses = np.sum(Y_scores[i, rows] < 0.5)  # count probable 0s\n",
    "            if support_misses < e / 2:\n",
    "                Y_pred[i, l] = 1\n",
    "    return Y_pred\n",
    "\n",
    "# -----------------------------\n",
    "# Evaluation\n",
    "# -----------------------------\n",
    "def precision_at_k(y_true, y_scores, k):\n",
    "    precisions = []\n",
    "    for yt, yp in zip(y_true, y_scores):\n",
    "        topk = np.argsort(-yp)[:k]\n",
    "        correct = yt[topk].sum()\n",
    "        precisions.append(correct / k)\n",
    "    return np.mean(precisions)\n",
    "\n",
    "# -----------------------------\n",
    "# Main\n",
    "# -----------------------------\n",
    "info_file = 'Delicious/Delicious_data.txt'\n",
    "train_file = 'Delicious/delicious_trSplit.txt'\n",
    "test_file  = 'Delicious/delicious_tstSplit.txt'\n",
    "n = 12920  # Number of training samples\n",
    "nt = 3185   # Number of test samples\n",
    "\n",
    "print(\"Loading training data...\")\n",
    "X_train, Y_train, p, d = load_delicious_dataset(info_file, train_file, n)\n",
    "print(\"Loading test data...\")\n",
    "X_test, Y_test, _, _ = load_delicious_dataset(info_file, test_file, nt)\n",
    "\n",
    "print(\"Building GT matrix...\")\n",
    "A = build_gt_matrix(d, m, method=GT_type)\n",
    "\n",
    "print(\"Training classifiers...\")\n",
    "classifiers = train_classifiers(X_train, Y_train, A)\n",
    "\n",
    "print(\"Predicting test scores...\")\n",
    "Y_scores = predict_all_scores(X_test, classifiers, A)\n",
    "\n",
    "print(\"Decoding predictions with thresholding...\")\n",
    "Y_pred = threshold_predictions(Y_scores, A, e)\n",
    "\n",
    "print(\"Evaluation\")\n",
    "k_eval = 10\n",
    "hl = hamming_loss(Y_test, Y_pred)\n",
    "p2 = precision_at_k(Y_test, Y_scores, k_eval)\n",
    "print(f\"Hamming Loss: {hl:.4f}\")\n",
    "print(f\"Precision@{k_eval} : {p2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9d3d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all values from k_eval 1 to 10\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 11), [precision_at_k(Y_test, Y_scores, k) for k in range(1, 11)], marker='o')\n",
    "plt.title('Precision@k vs k')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Precision@k')\n",
    "plt.xticks(range(1, 11))\n",
    "plt.grid()\n",
    "plt.savefig('precision_at_k.png')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
