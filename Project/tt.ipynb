{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ec5c0c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier  # for fitclinear equivalent\n",
    "from scipy.sparse import csr_matrix, lil_matrix, csc_matrix, issparse\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression  # or LinearSVC\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "import random\n",
    "import os\n",
    "\n",
    "# -----------------------------\n",
    "# Parameters for rcv1x\n",
    "# -----------------------------\n",
    "d = 2456\n",
    "e = 234 # 3k*logd\n",
    "k = 10\n",
    "m = 240\n",
    "n = 10000\n",
    "nt = 1000\n",
    "p = 6000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "90fef052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Dataset Loader\n",
    "# -----------------------------\n",
    "def parse_line_lbls_fts(line):\n",
    "    \"\"\"Parse a single line into labels and features.\"\"\"\n",
    "    lbls_part, fts_part = line.strip().split(' ', 1)\n",
    "    labels = [int(l) for l in lbls_part.split(',')]\n",
    "    features = []\n",
    "    for ft in fts_part.strip().split():\n",
    "        idx, val = ft.split(':')\n",
    "        features.append((int(idx), float(val)))\n",
    "    return labels, features\n",
    "\n",
    "def read_data(file_path, n, p, d, random_seed=42):\n",
    "    \"\"\"Reads a sparse matrix format dataset from a text file with optional constraints.\"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        num_inst, num_ft, num_lbl = map(int, f.readline().split())\n",
    "        lines = f.readlines()\n",
    "\n",
    "    if n is None:\n",
    "        n = num_inst\n",
    "    n = min(n, len(lines))\n",
    "\n",
    "    # Shuffle and select n lines\n",
    "    random.seed(random_seed)\n",
    "    selected_lines = random.sample(lines, n)\n",
    "\n",
    "    feature_data = []\n",
    "    feature_row = []\n",
    "    feature_col = []\n",
    "\n",
    "    label_data = []\n",
    "    label_row = []\n",
    "    label_col = []\n",
    "\n",
    "    for idx, line in enumerate(selected_lines):\n",
    "        labels, features = parse_line_lbls_fts(line)\n",
    "\n",
    "        for ft_id, ft_val in features:\n",
    "            if p is None or ft_id < p:\n",
    "                feature_row.append(ft_id)\n",
    "                feature_col.append(idx)\n",
    "                feature_data.append(ft_val)\n",
    "\n",
    "        for lbl_id in labels:\n",
    "            if d is None or lbl_id < d:\n",
    "                label_row.append(lbl_id)\n",
    "                label_col.append(idx)\n",
    "                label_data.append(1.0)\n",
    "\n",
    "    if p is None:\n",
    "        p = max(feature_row, default=0) + 1\n",
    "    if d is None:\n",
    "        d = max(label_row, default=0) + 1\n",
    "\n",
    "    ft_mat = csc_matrix((feature_data, (feature_row, feature_col)), shape=(p, n))\n",
    "    lbl_mat = csc_matrix((label_data, (label_row, label_col)), shape=(d, n))\n",
    "\n",
    "    return ft_mat, lbl_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "22ffed4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'RCV1-x/rcv1x_train.txt'\n",
    "X, Y = read_data(file,n, p, d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "119b3aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_disjunct(m, d, p1):\n",
    "    \"\"\"\n",
    "    Create a k-disjunct constant weight group testing matrix (sparse binarY).\n",
    "\n",
    "    Parameters:\n",
    "    m -- number of rows\n",
    "    d -- number of columns\n",
    "    p1 -- weight per column\n",
    "\n",
    "    Returns:\n",
    "    A -- sparse binarY matrix of shape m x d\n",
    "    \"\"\"\n",
    "    A2 = lil_matrix((m, d), dtype=int)\n",
    "\n",
    "    rep1 = int(np.floor(d / p1))\n",
    "    rep2 = int(np.ceil(m / rep1))\n",
    "    j1 = 0\n",
    "\n",
    "    for j2 in range(rep2):\n",
    "        if j2 == 0:\n",
    "            for j in range(rep1):\n",
    "                A2[j, j1:j1+p1] = 1\n",
    "                j1 += p1\n",
    "        else:\n",
    "            rn = np.random.permutation(d)\n",
    "            for j in range(rep1):\n",
    "                A2[(j2-1)*rep1 + j, :] = A2[j, rn]\n",
    "\n",
    "    A2 = A2[:m, :]\n",
    "    rd = np.random.permutation(d)\n",
    "    A2 = A2[:, rd]\n",
    "\n",
    "    return csc_matrix(A2)\n",
    "\n",
    "\n",
    "\n",
    "def Sel_c_k_disjunct(Y, m, n, k, c1):\n",
    "    \"\"\"\n",
    "    Generate a constant weight group testing matrix A.\n",
    "    \n",
    "    Parameters:\n",
    "    Y -- d x n label matrix (NumPY arraY or SciPY sparse matrix)\n",
    "    m -- Number of groups (rows of A)\n",
    "    n -- Number of training samples (columns in Y)\n",
    "    k -- Label sparsitY\n",
    "    c1 -- List of column sparsitY sweep values\n",
    "\n",
    "    Returns:\n",
    "    A -- m x d sparse binarY matrix\n",
    "    c -- selected column sparsitY value from c1\n",
    "    er -- minimum average Hamming loss error\n",
    "    \"\"\"\n",
    "    d, _ = Y.shape\n",
    "    Err = []\n",
    "    Atmp = []\n",
    "\n",
    "    for c1_val in c1:\n",
    "        p1 = int(np.floor(c1_val * d / m))\n",
    "        A = k_disjunct(m, d, p1)\n",
    "\n",
    "        Z = (A @ Y[:, :n]) > 0  # spones: convert to binarY (0/1)\n",
    "\n",
    "        ATp = A.transpose() @ Z\n",
    "        err = np.zeros(n)\n",
    "\n",
    "        for l in range(n):\n",
    "            Yp = np.zeros(d)\n",
    "            idx = np.argsort(-ATp[:, l])  # sort descending\n",
    "            Yp[idx[:k]] = 1\n",
    "            err[l] = np.sum(Yp != Y[:, l].toarray().flatten())\n",
    "\n",
    "        Err.append(np.mean(err))\n",
    "        Atmp.append(A)\n",
    "\n",
    "    min_idx = np.argmin(Err)\n",
    "    er = Err[min_idx]\n",
    "    A = Atmp[min_idx]\n",
    "    c = c1[min_idx]\n",
    "\n",
    "    return A, c, er\n",
    "\n",
    "\n",
    "def sort_sparse_mat(X):\n",
    "    \"\"\"\n",
    "    Sorts each row of sparse matrix X (m x n) bY descending value,\n",
    "    and returns a dense (m x n) matrix where each row contains\n",
    "    the indices of columns sorted in descending order of value.\n",
    "\n",
    "    Parameters:\n",
    "    X -- scipY.sparse.csr_matrix of shape (m, n)\n",
    "\n",
    "    Returns:\n",
    "    rank_mat -- numpY arraY of shape (m, n)\n",
    "    \"\"\"\n",
    "    if not isinstance(X, csr_matrix):\n",
    "        X = csr_matrix(X)\n",
    "\n",
    "    m, n = X.shape\n",
    "    rank_mat = np.zeros((m, n), dtype=int)\n",
    "\n",
    "    for i in range(m):\n",
    "        row = X.getrow(i)\n",
    "        cols = row.indices\n",
    "        vals = row.data\n",
    "\n",
    "        if len(vals) == 0:\n",
    "            continue\n",
    "\n",
    "        sorted_indices = np.argsort(-vals)  # descending sort\n",
    "        sorted_cols = cols[sorted_indices]\n",
    "\n",
    "        rank_mat[i, :len(sorted_cols)] = sorted_cols\n",
    "\n",
    "    return rank_mat\n",
    "\n",
    "\n",
    "def precision_k_new(score_mat, true_mat, K):\n",
    "    return _helper(score_mat, true_mat, K)\n",
    "\n",
    "def _helper(score_mat, true_mat, K):\n",
    "    num_inst = score_mat.shape[1]\n",
    "    num_lbl = score_mat.shape[0]\n",
    "\n",
    "    score_mat = csr_matrix(score_mat)\n",
    "    rank_mat = sort_sparse_mat(score_mat)  # custom ranking\n",
    "\n",
    "    mat = []\n",
    "    for j in range(num_inst):\n",
    "        tmp = rank_mat[:, j].copy()\n",
    "        tmp[tmp > K] = 0\n",
    "        mat.append((tmp > 0).astype(int))\n",
    "\n",
    "    mat = np.array(mat).T\n",
    "    mat = csr_matrix(mat).multiply(true_mat)\n",
    "    num = np.array(mat.sum(axis=0)).ravel()\n",
    "\n",
    "    P = np.zeros(K)\n",
    "    for k in range(1, K+1):\n",
    "        num2 = np.minimum(num, k)\n",
    "        P[k-1] = np.mean(num2 / k)\n",
    "\n",
    "    return P\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "def MLGT_train_test(X, Y, Xtest, Ytest, A, k):\n",
    "    \"\"\"\n",
    "    Train and evaluate MLGT with given data and parameters.\n",
    "\n",
    "    Parameters:\n",
    "    X, Y        -- Training feature and label matrices\n",
    "    Xtest, Ytest-- Testing feature and label matrices\n",
    "    A           -- Group testing matrix\n",
    "    k           -- Label sparsitY (number of labels per instance)\n",
    "\n",
    "    Returns:\n",
    "    Output -- dictionarY with precision, training time, test time, etc.\n",
    "    \"\"\"\n",
    "    m, d = A.shape\n",
    "    n = X.shape[0]\n",
    "    nt = Xtest.shape[0]\n",
    "    Ztest = np.zeros((m, nt))\n",
    "    Output = {}\n",
    "\n",
    "    # --- Training ---\n",
    "    t1 = time.process_time()\n",
    "    Y2 = (A @ Y) > 0  # Shape [m, n]\n",
    "    SVM = {}\n",
    "\n",
    "    for j in range(m):\n",
    "        y2 = Y2[j, :].toarray().ravel() if issparse(Y2) else Y2[j, :]\n",
    "        if np.count_nonzero(y2) == 0:\n",
    "            Ztest[j, :] = 0\n",
    "        else:\n",
    "            clf = LogisticRegression(solver='liblinear')\n",
    "            clf.fit(X, y2)\n",
    "            SVM[j] = clf\n",
    "\n",
    "\n",
    "    t2 = time.process_time()\n",
    "\n",
    "    # --- Testing ---\n",
    "    for l in range(m):\n",
    "        if l in SVM:\n",
    "            Ztest[l, :] = SVM[l].predict(Xtest)\n",
    "\n",
    "\n",
    "    Ztest = csr_matrix(Ztest)\n",
    "    ATp = A.transpose().dot(Ztest)\n",
    "\n",
    "    t3 = time.process_time()\n",
    "\n",
    "    # --- Evaluation ---\n",
    "    prec_k = precision_k_new(ATp, Ytest, k)\n",
    "\n",
    "    Output[\"Prec_k\"] = prec_k\n",
    "    Output[\"train_time\"] = t2 - t1\n",
    "    Output[\"test_time\"] = t3 - t2\n",
    "    Output[\"total_times\"] = t3 - t1\n",
    "\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0b38c7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded.\n"
     ]
    }
   ],
   "source": [
    "dir = 'RCV1-x'\n",
    "file_train = os.path.join(dir+'/', 'rcv1x_train.txt')\n",
    "file_test = os.path.join(dir+'/', 'rcv1x_test.txt')\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "X, Y = read_data(file_train, n, p, d)\n",
    "Xtest, Ytest = read_data(file_test, nt, p, d)\n",
    "\n",
    "X = X.T\n",
    "Xtest = Xtest.T\n",
    "print(\"Dataset loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fa6039d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLGT parameters\n",
    "c1 = list(range(10, 70, 10))  # column sparsitY sweep\n",
    "\n",
    "# --- CW (Constant Weight MLGT) ---\n",
    "A2, c, Err2 = Sel_c_k_disjunct(Y, m, n, k, c1)\n",
    "# print(A2.shape)\n",
    "\n",
    "start_test = time.time()\n",
    "Output2 = MLGT_train_test(X, Y, Xtest, Ytest, A2, k)\n",
    "end_test = time.time()\n",
    "\n",
    "\n",
    "CW_GT_Prec = [\n",
    "    Output2['Prec_k'][0],\n",
    "    Output2['Prec_k'][2],\n",
    "    Output2['Prec_k'][4]\n",
    "]\n",
    "CW_times = [Output2['train_time'], Output2['test_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2329dc1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Prec_k': array([0.01      , 0.005     , 0.00333333, 0.0025    , 0.002     ,\n",
       "        0.00166667, 0.00142857, 0.00125   , 0.00111111, 0.001     ]),\n",
       " 'train_time': 2.3918431820000023,\n",
       " 'test_time': 0.018048861000124816,\n",
       " 'total_times': 2.409892043000127}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201441ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
