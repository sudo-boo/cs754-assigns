{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "514f218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy.sparse import lil_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -----------------------------\n",
    "# Parameters\n",
    "# -----------------------------\n",
    "k = 10      # Max labels per sample\n",
    "e = 30      # Error correction parameter\n",
    "m = 240     # Number of classifiers\n",
    "n = 2000    # Training samples\n",
    "nt = 501    # Test samples\n",
    "p = 6000    # Feature dimension\n",
    "d = 2456   # Number of labels\n",
    "GT_type = \"sparse_rand\"  # Choose from: sparse_rand, expander, rs_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1927eed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# DATA LOADER\n",
    "# -------------------------------\n",
    "def load_dataset(path, n_samples, p, d):\n",
    "    X = lil_matrix((n_samples, p), dtype=np.float32)\n",
    "    Y = np.zeros((n_samples, d), dtype=np.int32)\n",
    "\n",
    "    with open(path, 'r') as f:\n",
    "        header = f.readline()  # skip header\n",
    "        for i, line in tqdm(enumerate(f), total=n_samples):\n",
    "            if i >= n_samples:\n",
    "                break\n",
    "            parts = line.strip().split()\n",
    "            if not parts:\n",
    "                continue\n",
    "            # Label parsing\n",
    "            label_tokens = parts[0].split(',')\n",
    "            for l in label_tokens:\n",
    "                if l.isdigit():\n",
    "                    idx = int(l)\n",
    "                    if 0 <= idx < d:\n",
    "                        Y[i, idx] = 1\n",
    "            # Feature parsing\n",
    "            for item in parts[1:]:\n",
    "                if ':' in item:\n",
    "                    try:\n",
    "                        idx, val = item.split(':')\n",
    "                        idx = int(idx)\n",
    "                        if idx < p:\n",
    "                            X[i, idx] = float(val)\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "    return X.tocsr(), Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d6be2339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# GT Matrix Construction\n",
    "# -----------------------------\n",
    "def build_gt_matrix(d, m, method=\"sparse_rand\"):\n",
    "    A = np.zeros((m, d), dtype=int)\n",
    "    if method == \"sparse_rand\":\n",
    "        for i in range(m):\n",
    "            indices = np.random.choice(d, size=(d // k), replace=False)\n",
    "            A[i, indices] = 1\n",
    "    elif method == \"expander\":\n",
    "        degree = d // k\n",
    "        for j in range(d):\n",
    "            neighbors = np.random.choice(m, degree, replace=False)\n",
    "            A[neighbors, j] = 1\n",
    "    elif method == \"rs_code\":\n",
    "        raise NotImplementedError(\"Reed-Solomon code based GT not implemented\")\n",
    "    else:\n",
    "        raise ValueError(\"Unknown GT matrix type\")\n",
    "    return A\n",
    "\n",
    "# -----------------------------\n",
    "# Train Classifiers (Binary Relevance on m meta-labels)\n",
    "# -----------------------------\n",
    "def encode_meta_labels(Y, A):\n",
    "    Z = (Y @ A.T) > 0\n",
    "    return Z.astype(int)\n",
    "\n",
    "def train_classifiers(X, Z, method=\"logistic\"):\n",
    "    classifiers = []\n",
    "    for j in range(Z.shape[1]):\n",
    "        if method == \"logistic\":\n",
    "            clf = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "        elif method == \"rf\":\n",
    "            clf = RandomForestClassifier(n_estimators=100, class_weight='balanced')\n",
    "        else:\n",
    "            raise ValueError(\"Unknown classifier\")\n",
    "        clf.fit(X, Z[:, j])\n",
    "        classifiers.append(clf)\n",
    "    return classifiers\n",
    "\n",
    "def predict_meta_labels(classifiers, X):\n",
    "    Z_pred = np.zeros((X.shape[0], len(classifiers)))\n",
    "    for j, clf in enumerate(classifiers):\n",
    "        Z_pred[:, j] = clf.predict(X)\n",
    "    return Z_pred\n",
    "\n",
    "def decode_labels(Z_pred, A, k):\n",
    "    Y_pred_scores = Z_pred @ A\n",
    "    topk = np.argsort(-Y_pred_scores, axis=1)[:, :k]\n",
    "    result = np.zeros((Z_pred.shape[0], A.shape[1]), dtype=int)\n",
    "    for i in range(Z_pred.shape[0]):\n",
    "        result[i, topk[i]] = 1\n",
    "    return result\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Evaluation\n",
    "# -----------------------------\n",
    "def precision_at_k(Y_true, Y_pred, k):\n",
    "    num = 0\n",
    "    denom = Y_true.shape[0]\n",
    "    for i in range(Y_true.shape[0]):\n",
    "        topk = np.argsort(-Y_pred[i])[:k]\n",
    "        num += np.sum(Y_true[i, topk])\n",
    "    return num / (k * denom)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d645ea50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 18690.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels: 2456\n",
      "Loading testing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [00:00<00:00, 18551.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Main\n",
    "# -----------------------------\n",
    "dir = 'RCV1-x/RCV1-x/'\n",
    "print(\"Loading training data...\")\n",
    "X_train, Y_train = load_dataset(os.path.join(dir, 'rcv1x_train.txt'), n, p, d)\n",
    "print(f\"Training labels: {d}\")\n",
    "\n",
    "print(\"Loading testing data...\")\n",
    "X_test, Y_test = load_dataset(os.path.join(dir, 'rcv1x_test.txt'), nt, p, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a4dc97ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check how many labels are unique in the training set\n",
    "# unique_labels = np.unique(Y_train, axis=0)\n",
    "# print(f\"Unique labels in training set: {unique_labels.shape[0]}\")\n",
    "# Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "aed2de7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building GT matrix...\n",
      "Encoding meta-labels...\n"
     ]
    }
   ],
   "source": [
    "print(\"Building GT matrix...\")\n",
    "A = build_gt_matrix(d, m, method=GT_type)\n",
    "\n",
    "print(\"Encoding meta-labels...\")\n",
    "Z_train = encode_meta_labels(Y_train, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8eafb39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifiers...\n"
     ]
    }
   ],
   "source": [
    "print(\"Training classifiers...\")\n",
    "classifiers = train_classifiers(X_train, Z_train, method=\"logistic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "43880b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting meta-labels...\n",
      "Decoding labels...\n",
      "Evaluation:\n",
      "Hamming Loss     : 0.0054\n",
      "Precision@10      : 0.0830\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicting meta-labels...\")\n",
    "Z_pred = predict_meta_labels(classifiers, X_test)\n",
    "\n",
    "print(\"Decoding labels...\")\n",
    "Y_test_pred = decode_labels(Z_pred, A, k=k)\n",
    "\n",
    "print(\"Evaluation:\")\n",
    "print(\"Hamming Loss     : {:.4f}\".format(hamming_loss(Y_test, Y_test_pred)))\n",
    "print(\"Precision@{}      : {:.4f}\".format(k, precision_at_k(Y_test, Y_test_pred, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5622dca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aip-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
