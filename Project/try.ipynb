{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "6e77499a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import hamming_loss\n",
    "from scipy.sparse import lil_matrix\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# -----------------------------\n",
    "# Parameters\n",
    "# -----------------------------\n",
    "k = 10\n",
    "m = 240\n",
    "e = 30\n",
    "n = 2000\n",
    "nt = 501\n",
    "p = 6000\n",
    "d = 2456\n",
    "GT_type = \"sparse_rand\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "8737e14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Dataset Loader\n",
    "# -----------------------------\n",
    "def load_dataset(path, n_samples, p, d):\n",
    "    X = lil_matrix((n_samples, p), dtype=np.float32)\n",
    "    Y = np.zeros((n_samples, d), dtype=np.int32)\n",
    "\n",
    "    with open(path, 'r') as f:\n",
    "        _ = f.readline()  # skip header\n",
    "        for i, line in tqdm(enumerate(f), total=n_samples):\n",
    "            if i >= n_samples:\n",
    "                break\n",
    "            parts = line.strip().split()\n",
    "            labels = parts[0].split(',')\n",
    "            for l in labels:\n",
    "                if l.isdigit():\n",
    "                    idx = int(l)\n",
    "                    if 0 <= idx < d:\n",
    "                        Y[i, idx] = 1\n",
    "            for item in parts[1:]:\n",
    "                if ':' in item:\n",
    "                    idx, val = item.split(':')\n",
    "                    idx = int(idx)\n",
    "                    if idx < p:\n",
    "                        X[i, idx] = float(val)\n",
    "    return X.tocsr(), Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "53e1b278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# GT Matrix Builders\n",
    "# -----------------------------\n",
    "def build_gt_matrix(d, m, method=\"sparse_rand\"):\n",
    "    if method == \"sparse_rand\":\n",
    "        A = np.zeros((m, d), dtype=int)\n",
    "        s = m // (k + 1)\n",
    "        for j in range(d):\n",
    "            ones = np.random.choice(m, size=s, replace=False)\n",
    "            A[ones, j] = 1\n",
    "    # elif method == \"expander\":\n",
    "    #     A = np.zeros((m, d), dtype=int)\n",
    "    #     deg = m // (k + 1)\n",
    "    #     for j in range(d):\n",
    "    #         ones = np.random.choice(m, size=deg, replace=False)\n",
    "    #         A[ones, j] = 1\n",
    "    # elif method == \"rs_code\":\n",
    "    #     np.random.seed(42)\n",
    "    #     A = np.random.randint(0, 2, size=(m, d))\n",
    "    # else:\n",
    "    #     raise ValueError(\"Unknown GT matrix type\")\n",
    "    return A\n",
    "\n",
    "# -----------------------------\n",
    "# -----------------------------\n",
    "# MLGT Training (Algorithm 1)\n",
    "# -----------------------------\n",
    "def train_classifiers(X, Y, A):\n",
    "    Z = np.zeros((X.shape[0], A.shape[0]), dtype=int)\n",
    "    for i in range(X.shape[0]):\n",
    "        Z[i] = np.any(A[:, Y[i] == 1], axis=1).astype(int)\n",
    "\n",
    "    classifiers = []\n",
    "    for j in tqdm(range(A.shape[0])):\n",
    "        clf = RandomForestClassifier(n_estimators=10, max_depth=5, random_state=42)\n",
    "        clf.fit(X.toarray(), Z[:, j])\n",
    "        classifiers.append(clf)\n",
    "    return classifiers\n",
    "\n",
    "# -----------------------------\n",
    "# MLGT Prediction (Algorithm 2)\n",
    "# -----------------------------\n",
    "def decode_prediction(x, classifiers, A, e):\n",
    "    m = len(classifiers)\n",
    "    z_hat = np.zeros(m, dtype=int)\n",
    "    for j, clf in enumerate(classifiers):\n",
    "        z_hat[j] = clf.predict(x)[0]\n",
    "        \n",
    "    d = A.shape[1]\n",
    "    y_hat = np.zeros(d, dtype=int)\n",
    "    for l in range(d):\n",
    "        if np.sum(np.logical_and(A[:, l], 1 - z_hat)) < e / 2:\n",
    "            y_hat[l] = 1\n",
    "    return y_hat\n",
    "\n",
    "def predict_all(X, classifiers, A, e):\n",
    "    preds = []\n",
    "    for i in tqdm(range(X.shape[0])):\n",
    "        preds.append(decode_prediction(X[i], classifiers, A, e))\n",
    "    return np.array(preds)\n",
    "\n",
    "# -----------------------------\n",
    "# Evaluation\n",
    "# -----------------------------\n",
    "def precision_at_k(y_true, y_pred, k):\n",
    "    precisions = []\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        topk = np.argsort(-yp)[:k]\n",
    "        correct = yt[topk].sum()\n",
    "        precisions.append(correct / k)\n",
    "    return np.mean(precisions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "e7457f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 19416.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [00:00<00:00, 19273.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building GT matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Main\n",
    "# -----------------------------\n",
    "dir = 'RCV1-x/RCV1-x/'\n",
    "file_train = os.path.join(dir, 'rcv1x_train.txt')\n",
    "file_test  = os.path.join(dir, 'rcv1x_test.txt')\n",
    "\n",
    "print(\"Loading training data...\")\n",
    "X_train, Y_train = load_dataset(file_train, n, p, d)\n",
    "# d = Y_train.shape[1]  # update d\n",
    "\n",
    "print(\"Loading test data...\")\n",
    "X_test, Y_test = load_dataset(file_test, nt, p, d)\n",
    "\n",
    "print(\"Building GT matrix...\")\n",
    "A = build_gt_matrix(d, m, method=GT_type)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "c5622dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifiers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:22<00:00, 10.79it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Training classifiers...\")\n",
    "classifiers = train_classifiers(X_train, Y_train, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "37cabc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [01:44<00:00,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation\n",
      "Hamming Loss: 0.0021\n",
      "Precision@10 : 0.0174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicting test set...\")\n",
    "Y_pred = predict_all(X_test, classifiers, A, e)\n",
    "\n",
    "print(\"Evaluation\")\n",
    "k_eval = 10\n",
    "hl = hamming_loss(Y_test, Y_pred)\n",
    "p2 = precision_at_k(Y_test, Y_pred, k_eval)\n",
    "print(f\"Hamming Loss: {hl:.4f}\")\n",
    "print(f\"Precision@{k_eval} : {p2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f275a47a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aip-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
